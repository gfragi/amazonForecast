{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing machine learning algorithms\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# Importing other packages\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neptune\n",
    "import tempfile\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "import my_functions as mf\n",
    "\n",
    "import mlflow\n",
    "import mlflow.catboost\n",
    "import os\n",
    "\n",
    "\n",
    "# Importing packages for machine learning operations\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the experiment name in MLflow\n",
    "instance_Family = 'GPU_instance'\n",
    "# General_purpose\n",
    "# Memory_optimized\n",
    "# Storage_optimized\n",
    "# Compute_optimized\n",
    "# GPU_instance\n",
    "\n",
    "outlier = 'zscore'\n",
    "\n",
    "# zscore\n",
    "# iqr\n",
    "# lof\n",
    "# isolation\n",
    "\n",
    "\n",
    "mlflow.set_experiment(instance_Family)\n",
    "mlflow.set_tracking_uri(\"file:///media/gfragi/data/BarraCuda/mlruns/mlruns/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some experiment tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set tags for the run\n",
    "tags = {\n",
    "    \"experiment\": \"catboost_regression\",\n",
    "    \"model_type\": \"CatBoostRegressor\",\n",
    "    # \"task_type\": \"CPU\",\n",
    "    \"dataset\": \"Amazon\",\n",
    "    \"year to predict\": \"2022\",\n",
    "    \"all years for prediction\": \"no\",\n",
    "    \"outlier\": outlier\n",
    "}\n",
    "\n",
    "# Set the tags for the current run\n",
    "mlflow.set_tags(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_all = pd.read_csv(\n",
    "    f'./data/amazon_22_quarters.csv', parse_dates=['EffectiveDate'])\n",
    "\n",
    "# data = data.drop(['OfferTermCode', 'instanceType', 'instanceFamily', 'OfferingClass'], axis=1)\n",
    "\n",
    "data_all = data_all.drop(['SKU', 'RateCode', 'OfferTermCode', 'Location', 'instanceFamily',\n",
    "                          'License Model', 'TermType', 'year', 'Tenancy', 'OfferingClass',\n",
    "                          'instanceType', 'Product Family', 'Current Generation',\n",
    "                          'License Model'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 554079 entries, 0 to 554078\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   PricePerUnit         554079 non-null  float64       \n",
      " 1   LeaseContractLength  554079 non-null  int64         \n",
      " 2   PurchaseOption       554079 non-null  object        \n",
      " 3   vCPU                 554079 non-null  int64         \n",
      " 4   Memory               554079 non-null  int64         \n",
      " 5   operatingSystem      554079 non-null  object        \n",
      " 6   networkPerformance   554079 non-null  float64       \n",
      " 7   EffectiveDate        554079 non-null  datetime64[ns]\n",
      " 8   DiskType             554079 non-null  object        \n",
      " 9   StorageSize          554079 non-null  int64         \n",
      " 10  Quarter              554079 non-null  int64         \n",
      " 11  YearQuarter          554079 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(5), object(4)\n",
      "memory usage: 50.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # replace USEast and USWest to US and EU to Europe\n",
    "# data_all = data_all.replace({'USEast': 'US', 'USWest': 'US', 'EU': 'Europe'})\n",
    "# data_all = data_all[(data_all['Location'] != \"Africa\") & (data_all['Location'] != \"MiddleEast\") & (data_all['Location']\n",
    "#                                                                                                    != \"Canada\") & (data_all['Location'] != \"SouthAmerica\") & (data_all['Location'] != \"AWSGovCloud\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all = data_all.drop(['Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create several new date time features\n",
    "data_all['year'] = data_all['EffectiveDate'].dt.year\n",
    "# data['day_of_year'] = data['EffectiveDate'].dt.dayofyear\n",
    "# data['weekday'] = data['EffectiveDate'].dt.weekday\n",
    "# data['week_of_year'] = data['EffectiveDate'].dt.week\n",
    "# data['day_of_month'] = data['EffectiveDate'].dt.day\n",
    "# data['quarter'] = data['EffectiveDate'].dt.quarter\n",
    "\n",
    "# data.drop('EffectiveDate', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PricePerUnit</th>\n",
       "      <th>LeaseContractLength</th>\n",
       "      <th>PurchaseOption</th>\n",
       "      <th>vCPU</th>\n",
       "      <th>Memory</th>\n",
       "      <th>operatingSystem</th>\n",
       "      <th>networkPerformance</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>DiskType</th>\n",
       "      <th>StorageSize</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>YearQuarter</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40800</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>2016Q3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11800</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Linux</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SSD</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2016Q3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Linux</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SSD</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2016Q3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.22600</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Linux</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SSD</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2016Q3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11600</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Linux</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SSD</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2016Q3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554074</th>\n",
       "      <td>3.83952</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>Windows</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>2022Q4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554075</th>\n",
       "      <td>3.74373</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>Windows</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>2022Q4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554076</th>\n",
       "      <td>1.80328</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>Windows</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>2022Q4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554077</th>\n",
       "      <td>0.71500</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Windows</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>468</td>\n",
       "      <td>4</td>\n",
       "      <td>2022Q4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554078</th>\n",
       "      <td>15.56115</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>Windows</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>3800</td>\n",
       "      <td>4</td>\n",
       "      <td>2022Q4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554079 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PricePerUnit  LeaseContractLength   PurchaseOption  vCPU  Memory  \\\n",
       "0            0.40800                    3  Partial Upfront     8      61   \n",
       "1            0.11800                    3  Partial Upfront     4       7   \n",
       "2            0.12400                    1  Partial Upfront     4       7   \n",
       "3            0.22600                    1       No Upfront     4       7   \n",
       "4            0.11600                    3  Partial Upfront     4       7   \n",
       "...              ...                  ...              ...   ...     ...   \n",
       "554074       3.83952                    1       No Upfront     8      32   \n",
       "554075       3.74373                    1       No Upfront     8      32   \n",
       "554076       1.80328                    3  Partial Upfront     8      32   \n",
       "554077       0.71500                    1       No Upfront     2      16   \n",
       "554078      15.56115                    1  Partial Upfront    64      12   \n",
       "\n",
       "       operatingSystem  networkPerformance EffectiveDate  DiskType  \\\n",
       "0                Linux                 1.0    2016-09-30       SSD   \n",
       "1                Linux                 0.3    2016-09-30       SSD   \n",
       "2                Linux                 0.3    2016-09-30       SSD   \n",
       "3                Linux                 0.3    2016-09-30       SSD   \n",
       "4                Linux                 0.3    2016-09-30       SSD   \n",
       "...                ...                 ...           ...       ...   \n",
       "554074         Windows             12500.0    2022-10-01       SSD   \n",
       "554075         Windows             12500.0    2022-10-01       SSD   \n",
       "554076         Windows             12500.0    2022-10-01       SSD   \n",
       "554077         Windows                10.0    2022-12-01  NVMe SSD   \n",
       "554078         Windows            100000.0    2022-12-01       SSD   \n",
       "\n",
       "        StorageSize  Quarter YearQuarter  year  \n",
       "0              1600        3      2016Q3  2016  \n",
       "1                80        3      2016Q3  2016  \n",
       "2                80        3      2016Q3  2016  \n",
       "3                80        3      2016Q3  2016  \n",
       "4                80        3      2016Q3  2016  \n",
       "...             ...      ...         ...   ...  \n",
       "554074          474        4      2022Q4  2022  \n",
       "554075          474        4      2022Q4  2022  \n",
       "554076          474        4      2022Q4  2022  \n",
       "554077          468        4      2022Q4  2022  \n",
       "554078         3800        4      2022Q4  2022  \n",
       "\n",
       "[554079 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.sort_values(by='EffectiveDate')\n",
    "data_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022    184168\n",
       "2020    112164\n",
       "2021    103740\n",
       "2019     72480\n",
       "2018     43773\n",
       "2017     19952\n",
       "2016     17802\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['year'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "if outlier == 'isolation':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit', 'vCPU', 'Memory']\n",
    "\n",
    "    # Create an Isolation Forest object\n",
    "    # Adjust the contamination parameter as needed\n",
    "    isolation_forest = IsolationForest(contamination=0.1)\n",
    "\n",
    "    # Fit the Isolation Forest model and predict outlier labels\n",
    "    outlier_labels = isolation_forest.fit_predict(data_all[columns_to_check])\n",
    "\n",
    "    # Identify outliers based on the predicted labels\n",
    "    outliers = data_all[outlier_labels == -1]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[outlier_labels != -1]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "if outlier == 'lof':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Create a LOF object\n",
    "    # Adjust parameters as needed\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "\n",
    "    # Fit the LOF model and predict outlier scores\n",
    "    outlier_scores = lof.fit_predict(data_all[columns_to_check])\n",
    "\n",
    "    # Identify outliers based on the predicted scores\n",
    "    outliers = data_all[outlier_scores == -1]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[outlier_scores != -1]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range (IQR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if outlier == 'iqr':\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Calculate the IQR for each column\n",
    "    Q1 = data_all[columns_to_check].quantile(0.25)\n",
    "    Q3 = data_all[columns_to_check].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define a threshold for identifying outliers\n",
    "    threshold = 2\n",
    "\n",
    "    # Determine the lower and upper bounds for outlier detection\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers by filtering the dataset\n",
    "    outliers = data_all[~((data_all[columns_to_check] >= lower_bound) & (\n",
    "        data_all[columns_to_check] <= upper_bound)).all(axis=1)]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[((data_all[columns_to_check] >= lower_bound) & (\n",
    "        data_all[columns_to_check] <= upper_bound)).all(axis=1)]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PricePerUnit  LeaseContractLength   PurchaseOption  vCPU  Memory  \\\n",
      "7409        17.87500                    3       No Upfront    32     244   \n",
      "7418        30.85800                    1  Partial Upfront   128     192   \n",
      "7433        28.92900                    3  Partial Upfront   128     192   \n",
      "7528        18.36400                    1       No Upfront    32     244   \n",
      "7554        15.52800                    1       No Upfront    32      60   \n",
      "...              ...                  ...              ...   ...     ...   \n",
      "554008      14.03152                    1  Partial Upfront    64      12   \n",
      "554009      13.74384                    1  Partial Upfront    64      12   \n",
      "554010      13.41242                    3  Partial Upfront    64      12   \n",
      "554011      27.05083                    3       No Upfront    64      12   \n",
      "554078      15.56115                    1  Partial Upfront    64      12   \n",
      "\n",
      "       operatingSystem  networkPerformance EffectiveDate DiskType  \\\n",
      "7409           Windows                10.0    2016-11-30      SSD   \n",
      "7418           Windows                 1.0    2016-10-31      SSD   \n",
      "7433           Windows                 1.0    2016-10-31      SSD   \n",
      "7528           Windows                10.0    2016-11-30      SSD   \n",
      "7554           Windows                 1.0    2016-10-31      SSD   \n",
      "...                ...                 ...           ...      ...   \n",
      "554008           Linux             25000.0    2022-10-01      SSD   \n",
      "554009           Linux             25000.0    2022-10-01      SSD   \n",
      "554010           Linux             25000.0    2022-10-01      SSD   \n",
      "554011           Linux             25000.0    2022-10-01      SSD   \n",
      "554078         Windows            100000.0    2022-12-01      SSD   \n",
      "\n",
      "        StorageSize  Quarter YearQuarter  year  \n",
      "7409           6400        4      2016Q4  2016  \n",
      "7418           3840        4      2016Q4  2016  \n",
      "7433           3840        4      2016Q4  2016  \n",
      "7528           6400        4      2016Q4  2016  \n",
      "7554            240        4      2016Q4  2016  \n",
      "...             ...      ...         ...   ...  \n",
      "554008         3800        4      2022Q4  2022  \n",
      "554009         3800        4      2022Q4  2022  \n",
      "554010         3800        4      2022Q4  2022  \n",
      "554011         3800        4      2022Q4  2022  \n",
      "554078         3800        4      2022Q4  2022  \n",
      "\n",
      "[65187 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "if outlier == 'zscore':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Compute the Z-scores for each data point\n",
    "    z_scores = np.abs(stats.zscore(data_all[columns_to_check]))\n",
    "\n",
    "    # Define a threshold for identifying outliers\n",
    "    threshold = 0.75\n",
    "\n",
    "    # Find the indices of outliers\n",
    "    outlier_indices = np.where(z_scores > threshold)\n",
    "\n",
    "    # Get the rows containing outliers\n",
    "    outliers = data_all.iloc[outlier_indices[0]]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all.drop(data_all.index[outlier_indices[0]])\n",
    "\n",
    "    # Print the outliers\n",
    "    print(outliers)\n",
    "\n",
    "    mlflow.log_param(\"z-threshold\", threshold)\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create a quarterly seasonality column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert EffectiveDate column to datetime format\n",
    "# data_all['EffectiveDate'] = pd.to_datetime(data_all['EffectiveDate'])\n",
    "\n",
    "# # Extract the quarter component from the EffectiveDate column\n",
    "# data_all['Quarter'] = data_all['EffectiveDate'].dt.quarter\n",
    "\n",
    "\n",
    "# # Combine year and quarter into a single column\n",
    "# data_all['YearQuarter'] = data_all['year'].astype(\n",
    "#     str) + '-Q' + data_all['Quarter'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all\n",
    "\n",
    "# data_all = data_all.drop(['Seasonality'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categorical = ['PurchaseOption','OfferingClass', 'Location', 'Tenancy', 'operatingSystem', 'DiskType']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%  =========== Prepare the Data for regression============\n",
    "\n",
    "# # Map binary categorical columns to numerical\n",
    "\n",
    "# categorical_binary = ['PurchaseOption']\n",
    "# data_all[categorical_binary] = data_all[categorical_binary].apply(\n",
    "#     mf.binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write the categorical values as a list\n",
    "# # categorical = ['operatingSystem', 'DiskType', 'Location', 'instanceFamily']\n",
    "# categorical = ['operatingSystem', 'DiskType']\n",
    "# categorical2numeric = pd.get_dummies(data_all[categorical], drop_first=False)\n",
    "\n",
    "# categorical2numeric_pred = pd.get_dummies(\n",
    "#     data_all[categorical], drop_first=False)\n",
    "\n",
    "# # Add the above results to the original dataframe df\n",
    "# data_all = pd.concat([data_all, categorical2numeric], axis=1)\n",
    "# data_all.drop(columns=categorical, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2017, 2018, 2019, 2020, 2021, 2022])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred = data_all[data_all['year'] > 2021]\n",
    "data_pred = data_pred.sort_values(by='EffectiveDate')\n",
    "data_pred = data_pred.reset_index(drop=True)\n",
    "data_pred.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_all[(data_all['year'] > 2020) & (data_all['year'] < 2022)]\n",
    "data = data.sort_values(by='EffectiveDate')\n",
    "data = data.reset_index(drop=True)\n",
    "data.year.unique()\n",
    "\n",
    "\n",
    "mlflow.log_param(\"Years used to predict\", data.year.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(['PricePerUnit', 'EffectiveDate', 'YearQuarter'], axis=1)\n",
    "y = data.PricePerUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # identify categorical features indices\n",
    "# def column_index(data, query_cols):\n",
    "#     cols = data.columns.values\n",
    "#     sidx = np.argsort(cols)\n",
    "#     return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]\n",
    "\n",
    "# categorical_features_indices = column_index(X, categorical)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoost Model Training\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fe54451deb4d01a9f1582872e4ca32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.0534168\ttest: 2.0798053\tbest: 2.0798053 (0)\ttotal: 49.3ms\tremaining: 2.41s\n",
      "1:\tlearn: 1.9803815\ttest: 2.0065484\tbest: 2.0065484 (1)\ttotal: 51.7ms\tremaining: 1.24s\n",
      "2:\tlearn: 1.9207877\ttest: 1.9471039\tbest: 1.9471039 (2)\ttotal: 53.6ms\tremaining: 840ms\n",
      "3:\tlearn: 1.8633417\ttest: 1.8894489\tbest: 1.8894489 (3)\ttotal: 55ms\tremaining: 633ms\n",
      "4:\tlearn: 1.8162071\ttest: 1.8418636\tbest: 1.8418636 (4)\ttotal: 56.7ms\tremaining: 510ms\n",
      "5:\tlearn: 1.7714793\ttest: 1.7977333\tbest: 1.7977333 (5)\ttotal: 58.1ms\tremaining: 426ms\n",
      "6:\tlearn: 1.7343713\ttest: 1.7599761\tbest: 1.7599761 (6)\ttotal: 59.6ms\tremaining: 366ms\n",
      "7:\tlearn: 1.7051624\ttest: 1.7309033\tbest: 1.7309033 (7)\ttotal: 61.1ms\tremaining: 321ms\n",
      "8:\tlearn: 1.6773737\ttest: 1.7025822\tbest: 1.7025822 (8)\ttotal: 62.6ms\tremaining: 285ms\n",
      "9:\tlearn: 1.6330351\ttest: 1.6573143\tbest: 1.6573143 (9)\ttotal: 64.9ms\tremaining: 260ms\n",
      "10:\tlearn: 1.5952405\ttest: 1.6188323\tbest: 1.6188323 (10)\ttotal: 66.7ms\tremaining: 236ms\n",
      "11:\tlearn: 1.5635358\ttest: 1.5858902\tbest: 1.5858902 (11)\ttotal: 68.2ms\tremaining: 216ms\n",
      "12:\tlearn: 1.5356040\ttest: 1.5568012\tbest: 1.5568012 (12)\ttotal: 69.8ms\tremaining: 199ms\n",
      "13:\tlearn: 1.5123374\ttest: 1.5325071\tbest: 1.5325071 (13)\ttotal: 71.2ms\tremaining: 183ms\n",
      "14:\tlearn: 1.4915194\ttest: 1.5111926\tbest: 1.5111926 (14)\ttotal: 72.6ms\tremaining: 169ms\n",
      "15:\tlearn: 1.4734614\ttest: 1.4925431\tbest: 1.4925431 (15)\ttotal: 74ms\tremaining: 157ms\n",
      "16:\tlearn: 1.4585093\ttest: 1.4768109\tbest: 1.4768109 (16)\ttotal: 75.5ms\tremaining: 146ms\n",
      "17:\tlearn: 1.4457749\ttest: 1.4635117\tbest: 1.4635117 (17)\ttotal: 76.9ms\tremaining: 137ms\n",
      "18:\tlearn: 1.4329579\ttest: 1.4499399\tbest: 1.4499399 (18)\ttotal: 78.4ms\tremaining: 128ms\n",
      "19:\tlearn: 1.4219338\ttest: 1.4382476\tbest: 1.4382476 (19)\ttotal: 80.1ms\tremaining: 120ms\n",
      "20:\tlearn: 1.4114357\ttest: 1.4275050\tbest: 1.4275050 (20)\ttotal: 81.6ms\tremaining: 113ms\n",
      "21:\tlearn: 1.4037845\ttest: 1.4196674\tbest: 1.4196674 (21)\ttotal: 83ms\tremaining: 106ms\n",
      "22:\tlearn: 1.3951644\ttest: 1.4104961\tbest: 1.4104961 (22)\ttotal: 85.1ms\tremaining: 99.9ms\n",
      "23:\tlearn: 1.3884951\ttest: 1.4037378\tbest: 1.4037378 (23)\ttotal: 87ms\tremaining: 94.2ms\n",
      "24:\tlearn: 1.3812005\ttest: 1.3962066\tbest: 1.3962066 (24)\ttotal: 88.5ms\tremaining: 88.5ms\n",
      "25:\tlearn: 1.3744636\ttest: 1.3890936\tbest: 1.3890936 (25)\ttotal: 89.9ms\tremaining: 83ms\n",
      "26:\tlearn: 1.3674739\ttest: 1.3821539\tbest: 1.3821539 (26)\ttotal: 91.5ms\tremaining: 77.9ms\n",
      "27:\tlearn: 1.3617143\ttest: 1.3759361\tbest: 1.3759361 (27)\ttotal: 93.4ms\tremaining: 73.4ms\n",
      "28:\tlearn: 1.3559387\ttest: 1.3699154\tbest: 1.3699154 (28)\ttotal: 95.2ms\tremaining: 68.9ms\n",
      "29:\tlearn: 1.3510803\ttest: 1.3648513\tbest: 1.3648513 (29)\ttotal: 96.7ms\tremaining: 64.5ms\n",
      "30:\tlearn: 1.3461533\ttest: 1.3596705\tbest: 1.3596705 (30)\ttotal: 98.3ms\tremaining: 60.3ms\n",
      "31:\tlearn: 1.3420135\ttest: 1.3556109\tbest: 1.3556109 (31)\ttotal: 100ms\tremaining: 56.3ms\n",
      "32:\tlearn: 1.3384503\ttest: 1.3516937\tbest: 1.3516937 (32)\ttotal: 102ms\tremaining: 52.3ms\n",
      "33:\tlearn: 1.3343186\ttest: 1.3473399\tbest: 1.3473399 (33)\ttotal: 103ms\tremaining: 48.5ms\n",
      "34:\tlearn: 1.3305678\ttest: 1.3431904\tbest: 1.3431904 (34)\ttotal: 105ms\tremaining: 44.8ms\n",
      "35:\tlearn: 1.3274515\ttest: 1.3398266\tbest: 1.3398266 (35)\ttotal: 107ms\tremaining: 41.5ms\n",
      "36:\tlearn: 1.3233839\ttest: 1.3356144\tbest: 1.3356144 (36)\ttotal: 108ms\tremaining: 38.1ms\n",
      "37:\tlearn: 1.3201036\ttest: 1.3319308\tbest: 1.3319308 (37)\ttotal: 110ms\tremaining: 34.9ms\n",
      "38:\tlearn: 1.3174557\ttest: 1.3290214\tbest: 1.3290214 (38)\ttotal: 112ms\tremaining: 31.6ms\n",
      "39:\tlearn: 1.3142070\ttest: 1.3252683\tbest: 1.3252683 (39)\ttotal: 114ms\tremaining: 28.4ms\n",
      "40:\tlearn: 1.3119848\ttest: 1.3230224\tbest: 1.3230224 (40)\ttotal: 115ms\tremaining: 25.3ms\n",
      "41:\tlearn: 1.3097873\ttest: 1.3209488\tbest: 1.3209488 (41)\ttotal: 117ms\tremaining: 22.3ms\n",
      "42:\tlearn: 1.3067824\ttest: 1.3174127\tbest: 1.3174127 (42)\ttotal: 119ms\tremaining: 19.3ms\n",
      "43:\tlearn: 1.3043111\ttest: 1.3146005\tbest: 1.3146005 (43)\ttotal: 120ms\tremaining: 16.4ms\n",
      "44:\tlearn: 1.3008664\ttest: 1.3107105\tbest: 1.3107105 (44)\ttotal: 122ms\tremaining: 13.5ms\n",
      "45:\tlearn: 1.2995523\ttest: 1.3092403\tbest: 1.3092403 (45)\ttotal: 123ms\tremaining: 10.7ms\n",
      "46:\tlearn: 1.2979515\ttest: 1.3074878\tbest: 1.3074878 (46)\ttotal: 125ms\tremaining: 7.99ms\n",
      "47:\tlearn: 1.2966434\ttest: 1.3061128\tbest: 1.3061128 (47)\ttotal: 127ms\tremaining: 5.29ms\n",
      "48:\tlearn: 1.2950360\ttest: 1.3041208\tbest: 1.3041208 (48)\ttotal: 129ms\tremaining: 2.62ms\n",
      "49:\tlearn: 1.2931703\ttest: 1.3020618\tbest: 1.3020618 (49)\ttotal: 130ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.302061801\n",
      "bestIteration = 49\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fa3855b46a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=50, depth=3, cat_features=['PurchaseOption', 'operatingSystem', 'DiskType', 'Quarter'],\n",
    "                          learning_rate=0.1, loss_function='RMSE')\n",
    "\n",
    "# cat_features=categorical_features_indices\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=(X_valid, y_valid), plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Regressor parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = CatBoostRegressor(iterations=15000,\n",
    "                          loss_function='RMSE',\n",
    "                          # 0.001 - 0.1 A lower learning rate results in slower but more precise convergence\n",
    "                          learning_rate=0.001,\n",
    "                          # 4 - 10  Higher values allow the model to capture more complex interactions but can increase the risk of overfitting.\n",
    "                          depth=16,\n",
    "                          custom_metric=['MAPE', 'RMSE', 'MAE', 'R2'],\n",
    "                          random_seed=42,\n",
    "                          bagging_temperature=0.2,  # 0 - 1\n",
    "                          # Can be 'Iter' or 'IncToDec'. 'Iter' stops training when the evaluation metric stops improving, and 'IncToDec' stops when the evaluation metric starts to worsen.\n",
    "                          od_type='Iter',\n",
    "                          metric_period=75,  # how frequently the evaluation metric is calculated during training\n",
    "                          task_type='GPU',  # Enable GPU training\n",
    "                          # number of iterations to wait for the evaluation metric to improve before stopping training.\n",
    "                          od_wait=100,\n",
    "                          cat_features=['PurchaseOption',\n",
    "                                        'operatingSystem', 'DiskType']\n",
    "                          )\n",
    "\n",
    "# Log specific parameters of the CatBoost model\n",
    "params_to_track = ['iterations', 'learning_rate', 'depth', 'loss_function', 'bagging_temperature',\n",
    "                   'random_seed', 'metric_period', 'od_wait', 'task_type']\n",
    "for param in params_to_track:\n",
    "    param_value = model.get_params().get(param)\n",
    "    mlflow.log_param(param, str(param_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b370320801dc4cddbca1cd3b64d9e53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.1377268\ttest: 2.1644172\tbest: 2.1644172 (0)\ttotal: 503ms\tremaining: 2h 5m 48s\n",
      "75:\tlearn: 2.0368145\ttest: 2.0627090\tbest: 2.0627090 (75)\ttotal: 27.8s\tremaining: 1h 30m 58s\n",
      "150:\tlearn: 1.9449415\ttest: 1.9698949\tbest: 1.9698949 (150)\ttotal: 54.5s\tremaining: 1h 29m 21s\n",
      "225:\tlearn: 1.8614748\ttest: 1.8857090\tbest: 1.8857090 (225)\ttotal: 1m 21s\tremaining: 1h 29m 4s\n",
      "300:\tlearn: 1.7859312\ttest: 1.8095392\tbest: 1.8095392 (300)\ttotal: 1m 47s\tremaining: 1h 27m 36s\n",
      "375:\tlearn: 1.7173934\ttest: 1.7405184\tbest: 1.7405184 (375)\ttotal: 2m 15s\tremaining: 1h 27m 41s\n",
      "450:\tlearn: 1.6554316\ttest: 1.6780893\tbest: 1.6780893 (450)\ttotal: 2m 43s\tremaining: 1h 28m 6s\n",
      "525:\tlearn: 1.5994885\ttest: 1.6217179\tbest: 1.6217179 (525)\ttotal: 3m 10s\tremaining: 1h 27m 29s\n",
      "600:\tlearn: 1.5493877\ttest: 1.5712328\tbest: 1.5712328 (600)\ttotal: 3m 37s\tremaining: 1h 26m 50s\n",
      "675:\tlearn: 1.5044390\ttest: 1.5260366\tbest: 1.5260366 (675)\ttotal: 4m 3s\tremaining: 1h 26m 8s\n",
      "750:\tlearn: 1.4641326\ttest: 1.4855626\tbest: 1.4855626 (750)\ttotal: 4m 31s\tremaining: 1h 26m\n",
      "825:\tlearn: 1.4279507\ttest: 1.4493028\tbest: 1.4493028 (825)\ttotal: 5m\tremaining: 1h 25m 56s\n",
      "900:\tlearn: 1.3956780\ttest: 1.4170291\tbest: 1.4170291 (900)\ttotal: 5m 28s\tremaining: 1h 25m 37s\n",
      "975:\tlearn: 1.3668672\ttest: 1.3883029\tbest: 1.3883029 (975)\ttotal: 5m 55s\tremaining: 1h 25m 8s\n",
      "1050:\tlearn: 1.3411441\ttest: 1.3627468\tbest: 1.3627468 (1050)\ttotal: 6m 22s\tremaining: 1h 24m 42s\n",
      "1125:\tlearn: 1.3181563\ttest: 1.3399522\tbest: 1.3399522 (1125)\ttotal: 6m 50s\tremaining: 1h 24m 20s\n",
      "1200:\tlearn: 1.2979068\ttest: 1.3199761\tbest: 1.3199761 (1200)\ttotal: 7m 18s\tremaining: 1h 23m 57s\n",
      "1275:\tlearn: 1.2796826\ttest: 1.3020564\tbest: 1.3020564 (1275)\ttotal: 7m 47s\tremaining: 1h 23m 51s\n",
      "1350:\tlearn: 1.2636390\ttest: 1.2862956\tbest: 1.2862956 (1350)\ttotal: 8m 16s\tremaining: 1h 23m 37s\n",
      "1425:\tlearn: 1.2494870\ttest: 1.2724619\tbest: 1.2724619 (1425)\ttotal: 8m 44s\tremaining: 1h 23m 9s\n",
      "1500:\tlearn: 1.2367155\ttest: 1.2601073\tbest: 1.2601073 (1500)\ttotal: 9m 14s\tremaining: 1h 23m 10s\n",
      "1575:\tlearn: 1.2254500\ttest: 1.2492207\tbest: 1.2492207 (1575)\ttotal: 9m 44s\tremaining: 1h 22m 57s\n",
      "1650:\tlearn: 1.2155220\ttest: 1.2395996\tbest: 1.2395996 (1650)\ttotal: 10m 11s\tremaining: 1h 22m 24s\n",
      "1725:\tlearn: 1.2066945\ttest: 1.2311822\tbest: 1.2311822 (1725)\ttotal: 10m 41s\tremaining: 1h 22m 10s\n",
      "1800:\tlearn: 1.1988950\ttest: 1.2238178\tbest: 1.2238178 (1800)\ttotal: 11m 10s\tremaining: 1h 21m 51s\n",
      "1875:\tlearn: 1.1918571\ttest: 1.2172184\tbest: 1.2172184 (1875)\ttotal: 11m 40s\tremaining: 1h 21m 40s\n",
      "1950:\tlearn: 1.1857148\ttest: 1.2115196\tbest: 1.2115196 (1950)\ttotal: 12m 8s\tremaining: 1h 21m 12s\n",
      "2025:\tlearn: 1.1802678\ttest: 1.2064373\tbest: 1.2064373 (2025)\ttotal: 12m 34s\tremaining: 1h 20m 33s\n",
      "2100:\tlearn: 1.1753083\ttest: 1.2019721\tbest: 1.2019721 (2100)\ttotal: 13m 4s\tremaining: 1h 20m 15s\n",
      "2175:\tlearn: 1.1709260\ttest: 1.1980328\tbest: 1.1980328 (2175)\ttotal: 13m 32s\tremaining: 1h 19m 49s\n",
      "2250:\tlearn: 1.1670390\ttest: 1.1945940\tbest: 1.1945940 (2250)\ttotal: 14m\tremaining: 1h 19m 21s\n",
      "2325:\tlearn: 1.1635437\ttest: 1.1915485\tbest: 1.1915485 (2325)\ttotal: 14m 28s\tremaining: 1h 18m 54s\n",
      "2400:\tlearn: 1.1603474\ttest: 1.1888515\tbest: 1.1888515 (2400)\ttotal: 14m 59s\tremaining: 1h 18m 38s\n",
      "2475:\tlearn: 1.1575175\ttest: 1.1864751\tbest: 1.1864751 (2475)\ttotal: 15m 28s\tremaining: 1h 18m 16s\n",
      "2550:\tlearn: 1.1549312\ttest: 1.1843737\tbest: 1.1843737 (2550)\ttotal: 15m 58s\tremaining: 1h 17m 56s\n",
      "2625:\tlearn: 1.1525924\ttest: 1.1825186\tbest: 1.1825186 (2625)\ttotal: 16m 27s\tremaining: 1h 17m 33s\n",
      "2700:\tlearn: 1.1504642\ttest: 1.1808710\tbest: 1.1808710 (2700)\ttotal: 16m 56s\tremaining: 1h 17m 9s\n",
      "2775:\tlearn: 1.1486049\ttest: 1.1794596\tbest: 1.1794596 (2775)\ttotal: 17m 25s\tremaining: 1h 16m 41s\n",
      "2850:\tlearn: 1.1468604\ttest: 1.1782448\tbest: 1.1782448 (2850)\ttotal: 17m 55s\tremaining: 1h 16m 24s\n",
      "2925:\tlearn: 1.1453043\ttest: 1.1771592\tbest: 1.1771592 (2925)\ttotal: 18m 25s\tremaining: 1h 16m 1s\n",
      "3000:\tlearn: 1.1438680\ttest: 1.1761927\tbest: 1.1761927 (3000)\ttotal: 18m 54s\tremaining: 1h 15m 36s\n",
      "3075:\tlearn: 1.1425597\ttest: 1.1753607\tbest: 1.1753607 (3075)\ttotal: 19m 23s\tremaining: 1h 15m 10s\n",
      "3150:\tlearn: 1.1413346\ttest: 1.1746172\tbest: 1.1746172 (3150)\ttotal: 19m 53s\tremaining: 1h 14m 48s\n",
      "3225:\tlearn: 1.1402491\ttest: 1.1739672\tbest: 1.1739672 (3225)\ttotal: 20m 21s\tremaining: 1h 14m 18s\n",
      "3300:\tlearn: 1.1392317\ttest: 1.1734035\tbest: 1.1734035 (3300)\ttotal: 20m 51s\tremaining: 1h 13m 55s\n",
      "3375:\tlearn: 1.1382624\ttest: 1.1729138\tbest: 1.1729138 (3375)\ttotal: 21m 22s\tremaining: 1h 13m 35s\n",
      "3450:\tlearn: 1.1373606\ttest: 1.1724867\tbest: 1.1724867 (3450)\ttotal: 21m 52s\tremaining: 1h 13m 11s\n",
      "3525:\tlearn: 1.1365568\ttest: 1.1721075\tbest: 1.1721075 (3525)\ttotal: 22m 20s\tremaining: 1h 12m 40s\n",
      "3600:\tlearn: 1.1357466\ttest: 1.1717658\tbest: 1.1717658 (3600)\ttotal: 22m 51s\tremaining: 1h 12m 22s\n",
      "3675:\tlearn: 1.1349608\ttest: 1.1714720\tbest: 1.1714720 (3675)\ttotal: 23m 23s\tremaining: 1h 12m 3s\n",
      "3750:\tlearn: 1.1342760\ttest: 1.1711790\tbest: 1.1711790 (3750)\ttotal: 23m 53s\tremaining: 1h 11m 39s\n",
      "3825:\tlearn: 1.1336350\ttest: 1.1709598\tbest: 1.1709598 (3825)\ttotal: 24m 22s\tremaining: 1h 11m 11s\n",
      "3900:\tlearn: 1.1329533\ttest: 1.1707368\tbest: 1.1707368 (3900)\ttotal: 24m 54s\tremaining: 1h 10m 51s\n",
      "3975:\tlearn: 1.1323410\ttest: 1.1705417\tbest: 1.1705417 (3975)\ttotal: 25m 26s\tremaining: 1h 10m 31s\n",
      "4050:\tlearn: 1.1317716\ttest: 1.1703858\tbest: 1.1703858 (4050)\ttotal: 25m 57s\tremaining: 1h 10m 10s\n",
      "4125:\tlearn: 1.1312061\ttest: 1.1702302\tbest: 1.1702302 (4125)\ttotal: 26m 29s\tremaining: 1h 9m 49s\n",
      "4200:\tlearn: 1.1306998\ttest: 1.1700827\tbest: 1.1700827 (4200)\ttotal: 26m 59s\tremaining: 1h 9m 22s\n",
      "4275:\tlearn: 1.1302311\ttest: 1.1699819\tbest: 1.1699819 (4275)\ttotal: 27m 27s\tremaining: 1h 8m 52s\n",
      "4350:\tlearn: 1.1297477\ttest: 1.1698697\tbest: 1.1698697 (4350)\ttotal: 28m\tremaining: 1h 8m 32s\n",
      "4425:\tlearn: 1.1292949\ttest: 1.1697781\tbest: 1.1697781 (4425)\ttotal: 28m 29s\tremaining: 1h 8m 4s\n",
      "4500:\tlearn: 1.1288568\ttest: 1.1696956\tbest: 1.1696956 (4499)\ttotal: 28m 59s\tremaining: 1h 7m 36s\n",
      "4575:\tlearn: 1.1284428\ttest: 1.1696456\tbest: 1.1696456 (4575)\ttotal: 29m 27s\tremaining: 1h 7m 6s\n",
      "4650:\tlearn: 1.1280012\ttest: 1.1695935\tbest: 1.1695935 (4650)\ttotal: 29m 58s\tremaining: 1h 6m 42s\n",
      "4725:\tlearn: 1.1276271\ttest: 1.1695359\tbest: 1.1695359 (4725)\ttotal: 30m 30s\tremaining: 1h 6m 18s\n",
      "4800:\tlearn: 1.1272623\ttest: 1.1694905\tbest: 1.1694905 (4800)\ttotal: 30m 58s\tremaining: 1h 5m 48s\n",
      "4875:\tlearn: 1.1268773\ttest: 1.1694614\tbest: 1.1694614 (4875)\ttotal: 31m 29s\tremaining: 1h 5m 22s\n",
      "4950:\tlearn: 1.1265421\ttest: 1.1694185\tbest: 1.1694181 (4949)\ttotal: 31m 57s\tremaining: 1h 4m 51s\n",
      "5025:\tlearn: 1.1261966\ttest: 1.1693805\tbest: 1.1693804 (5021)\ttotal: 32m 28s\tremaining: 1h 4m 26s\n",
      "5100:\tlearn: 1.1258730\ttest: 1.1693624\tbest: 1.1693586 (5071)\ttotal: 32m 57s\tremaining: 1h 3m 58s\n",
      "5175:\tlearn: 1.1255748\ttest: 1.1693486\tbest: 1.1693486 (5175)\ttotal: 33m 26s\tremaining: 1h 3m 28s\n",
      "5250:\tlearn: 1.1252698\ttest: 1.1693303\tbest: 1.1693303 (5250)\ttotal: 33m 54s\tremaining: 1h 2m 57s\n",
      "5325:\tlearn: 1.1250045\ttest: 1.1693143\tbest: 1.1693093 (5317)\ttotal: 34m 22s\tremaining: 1h 2m 25s\n",
      "5400:\tlearn: 1.1246996\ttest: 1.1693122\tbest: 1.1693082 (5383)\ttotal: 34m 50s\tremaining: 1h 1m 54s\n",
      "5475:\tlearn: 1.1244250\ttest: 1.1693093\tbest: 1.1693059 (5443)\ttotal: 35m 19s\tremaining: 1h 1m 27s\n",
      "5550:\tlearn: 1.1241735\ttest: 1.1692963\tbest: 1.1692944 (5542)\ttotal: 35m 49s\tremaining: 1h 59s\n",
      "5625:\tlearn: 1.1238838\ttest: 1.1693178\tbest: 1.1692944 (5542)\ttotal: 36m 20s\tremaining: 1h 32s\n",
      "bestTest = 1.169294395\n",
      "bestIteration = 5542\n",
      "Shrink model to first 5543 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fa387c50370>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          eval_set=(X_valid, y_valid),\n",
    "          use_best_model=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/02 06:09:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpa3ibdc35/model, flavor: catboost), fall back to return ['catboost==1.2']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "mlflow.catboost.log_model(model, \"catboost_model\")\n",
    "\n",
    "best_iteration = model.get_best_iteration()\n",
    "\n",
    "mlflow.log_metric('best_iteration', best_iteration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': X.columns})\n",
    "fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[\n",
    "                              True, False]).iloc[-30:]\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "    x=fea_imp['imp'],\n",
    "    y=fea_imp['col'],\n",
    "    orientation='h',\n",
    "    marker=dict(color=fea_imp['imp'], colorbar=dict(title='Importance'))\n",
    "\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CatBoost - Feature Importance - All',\n",
    "    yaxis=dict(title='Features'),\n",
    "    xaxis=dict(title='Importance'),\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"temp/feature_importance_all.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log feature importance - mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance values and feature names from your CatBoost model\n",
    "feature_importance = model.get_feature_importance()\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame to store the feature importance values and feature names\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "# Create a temporary file to save the feature importance DataFrame\n",
    "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as temp_file:\n",
    "    # Save the feature importance DataFrame as a CSV file\n",
    "    feature_importance_df.to_csv(temp_file, index=False)\n",
    "\n",
    "# Log the feature importance CSV file as an artifact in MLflow\n",
    "mlflow.log_artifact(temp_file.name, \"feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import tempfile\n",
    "\n",
    "# # Define the years sets\n",
    "# years_sets = [\n",
    "#     [2020, 2021],\n",
    "#     [2019, 2020, 2021],\n",
    "#     [2018, 2019, 2020, 2021],\n",
    "#     [2021]\n",
    "# ]\n",
    "\n",
    "# # Create a DataFrame to store the feature importance values and feature names\n",
    "# feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "# # Insert the year sets as the first column in the DataFrame\n",
    "# feature_importance_df.insert(0, 'Year Sets', years_sets)\n",
    "\n",
    "# # Create a temporary file to save the feature importance DataFrame\n",
    "# with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as temp_file:\n",
    "#     # Save the feature importance DataFrame as a CSV file\n",
    "#     feature_importance_df.to_csv(temp_file, index=False)\n",
    "\n",
    "# # Log the feature importance CSV file as an artifact in MLflow\n",
    "# mlflow.log_artifact(temp_file.name, \"feature_importance.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation:\n",
      "{'iterations': 15000, 'learning_rate': 0.001, 'depth': 16, 'loss_function': 'RMSE', 'od_wait': 100, 'od_type': 'Iter', 'random_seed': 42, 'metric_period': 75, 'custom_metric': ['MAPE', 'RMSE', 'MAE', 'R2'], 'bagging_temperature': 0.2, 'task_type': 'GPU', 'cat_features': ['PurchaseOption', 'operatingSystem', 'DiskType']}\n",
      "RMSE: 1.1692944184974097\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Model evaluation:')\n",
    "print(model.get_params())\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_valid, model.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn': {'MAE': 0.5923814971470504, 'MAPE': 0.26801998714972497, 'R2': 0.7239675368347193, 'RMSE': 1.12388382219725}, 'validation': {'MAE': 0.619836912495371, 'MAPE': 0.27529402555754434, 'R2': 0.7085045200099078, 'RMSE': 1.1692943947126397}}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_best_score())\n",
    "\n",
    "# Flatten and log the best scores as parameters in MLflow\n",
    "best_scores = model.get_best_score()\n",
    "for stage, metrics in best_scores.items():\n",
    "    for metric, value in metrics.items():\n",
    "        mlflow.log_metric(f'{stage}_{metric}', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the MLflow run\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish without shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# pool = cb.Pool(X_valid, y_valid)\n",
    "\n",
    "\n",
    "# # Compute SHAP values\n",
    "# shap_values = model.get_feature_importance(pool, type='ShapValues')\n",
    "\n",
    "# # Convert SHAP values to a DataFrame\n",
    "# shap_df = pd.DataFrame(shap_values[:, :-1], columns=X_valid.columns)\n",
    "\n",
    "# # Log the SHAP values as an artifact in MLflow\n",
    "# shap_df.to_csv(\"shap_values.csv\", index=False)\n",
    "# mlflow.log_artifact(\"shap_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude the constant offset column from shap_values\n",
    "# shap_values = shap_values[:, :-1]\n",
    "\n",
    "# # Create a SHAP summary plot\n",
    "# shap.summary_plot(shap_values, X_valid)\n",
    "\n",
    "# # Save the plot as an artifact in MLflow\n",
    "# shap_plot_path = 'shap_summary_plot.png'\n",
    "# shap.summary_plot(shap_values, X_valid, show=False)\n",
    "# plt.savefig(shap_plot_path)\n",
    "# mlflow.log_artifact(shap_plot_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs Actual Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predict(data,\n\u001b[1;32m      2\u001b[0m         prediction_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m         ntree_start\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      4\u001b[0m         ntree_end\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      5\u001b[0m         thread_count\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict(data,\n",
    "        prediction_type=None,\n",
    "        ntree_start=0,\n",
    "        ntree_end=0,\n",
    "        thread_count=-1,\n",
    "        verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=2]=\"No Upfront\": Cannot convert 'b'No Upfront'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2288\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1141\u001b[0m, in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:951\u001b[0m, in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'No Upfront'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m data_pred \u001b[39m=\u001b[39m data_pred\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mYearQuarter\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# data_pred_tmp = data_pred.drop(['PricePerUnit'], axis=1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(data_pred)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create a DataFrame with the predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m predictions_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictions, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Phd_projects/PriceIndex/price39_env/lib/python3.9/site-packages/catboost/core.py:5779\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5777\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5778\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5779\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m~/Phd_projects/PriceIndex/price39_env/lib/python3.9/site-packages/catboost/core.py:2543\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2542\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2543\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2544\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2546\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/Phd_projects/PriceIndex/price39_env/lib/python3.9/site-packages/catboost/core.py:2523\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2521\u001b[0m is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n\u001b[0;32m-> 2523\u001b[0m     data \u001b[39m=\u001b[39m Pool(\n\u001b[1;32m   2524\u001b[0m         data\u001b[39m=\u001b[39;49m[data] \u001b[39mif\u001b[39;49;00m is_single_object \u001b[39melse\u001b[39;49;00m data,\n\u001b[1;32m   2525\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   2526\u001b[0m         cat_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cat_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2527\u001b[0m         text_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2528\u001b[0m         embedding_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_embedding_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2529\u001b[0m         thread_count\u001b[39m=\u001b[39;49mthread_count\n\u001b[1;32m   2530\u001b[0m     )\n\u001b[1;32m   2531\u001b[0m \u001b[39mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[0;32m~/Phd_projects/PriceIndex/price39_env/lib/python3.9/site-packages/catboost/core.py:792\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    787\u001b[0m             \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    788\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    789\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpython objects.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m             )\n\u001b[0;32m--> 792\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[1;32m    793\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m \u001b[39msuper\u001b[39m(Pool, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/Phd_projects/PriceIndex/price39_env/lib/python3.9/site-packages/catboost/core.py:1419\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mif\u001b[39;00m feature_tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1418\u001b[0m     feature_tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1419\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[1;32m   1420\u001b[0m                 group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n",
      "File \u001b[0;32m_catboost.pyx:3955\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4005\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3821\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2787\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2329\u001b[0m, in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2290\u001b[0m, in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=2]=\"No Upfront\": Cannot convert 'b'No Upfront'' to float"
     ]
    }
   ],
   "source": [
    "data_pred = data_pred.drop(['YearQuarter'], axis=1)\n",
    "\n",
    "# data_pred_tmp = data_pred.drop(['PricePerUnit'], axis=1)\n",
    "predictions = model.predict(data_pred)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predictions'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('temp/predictions.csv', index=False)\n",
    "\n",
    "# Log the predictions CSV file as an artifact in MLflow\n",
    "mlflow.log_artifact('temp/predictions.csv', 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_prices = data_pred.PricePerUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a line plot using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(len(actual_prices))),\n",
    "              y=actual_prices, mode='lines', name='Actual'))\n",
    "fig.add_trace(go.Scatter(x=list(range(len(predictions))),\n",
    "              y=predictions, mode='lines', name='Predicted'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Prices for 2022',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='Price')\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"temp/actual_predicted.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(actual_prices, predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = actual_prices - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(actual_prices, predictions, c=error, cmap='coolwarm')\n",
    "plt.plot(np.linspace(min(actual_prices), max(actual_prices), 100), np.linspace(\n",
    "    min(actual_prices), max(actual_prices), 100), color='black', linestyle='--')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot using Plotly\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=actual_prices,\n",
    "    y=predictions,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=error,\n",
    "        colorscale='Viridis',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title='Error')\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Prices',\n",
    "    xaxis=dict(title='Actual Prices'),\n",
    "    yaxis=dict(title='Predicted Prices')\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"temp/actual_predicted_errors.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "mse = mean_squared_error(actual_prices, predictions)\n",
    "rmse = mean_squared_error(actual_prices, predictions, squared=False)\n",
    "mae = mean_absolute_error(actual_prices, predictions)\n",
    "r2 = r2_score(actual_prices, predictions)\n",
    "mape = mean_absolute_percentage_error(actual_prices, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"MSE\", mse)\n",
    "mlflow.log_metric(\"RMSE\", rmse)\n",
    "mlflow.log_metric(\"MAE\", mae)\n",
    "mlflow.log_metric(\"MAPE\", mape)\n",
    "mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "# mlflow.log_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print('MAPE:', mape)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/ad-demand-forecast-with-catboost-lightgbm-819e5073cd3e\n",
    "\n",
    "https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# End the MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price39_env",
   "language": "python",
   "name": "price39_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
