{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing machine learning algorithms\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# Importing other packages\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neptune\n",
    "import tempfile\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "import my_functions as mf\n",
    "\n",
    "import mlflow\n",
    "import mlflow.catboost\n",
    "import os\n",
    "\n",
    "\n",
    "# Importing packages for machine learning operations\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/gfragi/Phd_projects/amazonForecast/mlruns/933858221367283980', creation_time=1687250674267, experiment_id='933858221367283980', last_update_time=1687250674267, lifecycle_stage='active', name='Memory_optimized', tags={}>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow.set_tracking_uri(\"https://dagshub.com/gfragi/PriceIndex.mlflow\")\n",
    "\n",
    "\n",
    "# Set the experiment name in MLflow\n",
    "instance_Family = 'Memory_optimized'\n",
    "# General_purpose\n",
    "# Memory_optimized\n",
    "# Storage_optimized\n",
    "# Compute_optimized\n",
    "# GPU_instance\n",
    "\n",
    "outlier = 'zscore'\n",
    "\n",
    "# zscore\n",
    "# iqr\n",
    "# lof\n",
    "# isolation\n",
    "\n",
    "\n",
    "mlflow.set_experiment(instance_Family)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some experiment tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set tags for the run\n",
    "tags = {\n",
    "    \"experiment\": \"catboost_regression\",\n",
    "    \"model_type\": \"CatBoostRegressor\",\n",
    "    # \"task_type\": \"CPU\",\n",
    "    \"dataset\": \"Amazon\",\n",
    "    \"year to predict\": \"2022\",\n",
    "    \"all years for prediction\": \"no\",\n",
    "    \"outlier\": outlier\n",
    "}\n",
    "\n",
    "# Set the tags for the current run\n",
    "mlflow.set_tags(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_all = pd.read_csv(\n",
    "    f'./data/instFamily_subsets/{instance_Family}_subset.csv', parse_dates=['EffectiveDate'])\n",
    "\n",
    "# data = data.drop(['OfferTermCode', 'instanceType', 'instanceFamily', 'OfferingClass'], axis=1)\n",
    "\n",
    "data_all = data_all.drop(['OfferTermCode', 'instanceFamily', 'Location',\n",
    "                         'year', 'Tenancy', 'OfferingClass', 'instanceType'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176008 entries, 0 to 176007\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   PricePerUnit         176008 non-null  float64       \n",
      " 1   LeaseContractLength  176008 non-null  int64         \n",
      " 2   PurchaseOption       176008 non-null  object        \n",
      " 3   vCPU                 176008 non-null  int64         \n",
      " 4   Memory               176008 non-null  int64         \n",
      " 5   operatingSystem      176008 non-null  object        \n",
      " 6   networkPerformance   176008 non-null  float64       \n",
      " 7   EffectiveDate        176008 non-null  datetime64[ns]\n",
      " 8   DiskType             176008 non-null  object        \n",
      " 9   StorageSize          176008 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(3)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # replace USEast and USWest to US and EU to Europe\n",
    "# data_all = data_all.replace({'USEast': 'US', 'USWest': 'US', 'EU': 'Europe'})\n",
    "# data_all = data_all[(data_all['Location'] != \"Africa\") & (data_all['Location'] != \"MiddleEast\") & (data_all['Location']\n",
    "#                                                                                                    != \"Canada\") & (data_all['Location'] != \"SouthAmerica\") & (data_all['Location'] != \"AWSGovCloud\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all = data_all.drop(['Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create several new date time features\n",
    "data_all['year'] = data_all['EffectiveDate'].dt.year\n",
    "# data['day_of_year'] = data['EffectiveDate'].dt.dayofyear\n",
    "# data['weekday'] = data['EffectiveDate'].dt.weekday\n",
    "# data['week_of_year'] = data['EffectiveDate'].dt.week\n",
    "# data['day_of_month'] = data['EffectiveDate'].dt.day\n",
    "# data['quarter'] = data['EffectiveDate'].dt.quarter\n",
    "\n",
    "# data.drop('EffectiveDate', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PricePerUnit</th>\n",
       "      <th>LeaseContractLength</th>\n",
       "      <th>PurchaseOption</th>\n",
       "      <th>vCPU</th>\n",
       "      <th>Memory</th>\n",
       "      <th>operatingSystem</th>\n",
       "      <th>networkPerformance</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>DiskType</th>\n",
       "      <th>StorageSize</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0605</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RHEL_HA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1403</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RHEL_HA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1466</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RHEL_HA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1231</td>\n",
       "      <td>3</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RHEL_HA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0721</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RHEL_HA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176003</th>\n",
       "      <td>4.1430</td>\n",
       "      <td>3</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176004</th>\n",
       "      <td>3.7550</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176005</th>\n",
       "      <td>3.3360</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176006</th>\n",
       "      <td>2.1700</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176007</th>\n",
       "      <td>4.6010</td>\n",
       "      <td>3</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176008 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PricePerUnit  LeaseContractLength   PurchaseOption  vCPU  Memory  \\\n",
       "0             0.0605                    3  Partial Upfront     1       8   \n",
       "1             0.1403                    1       No Upfront     1       8   \n",
       "2             0.1466                    1       No Upfront     1       8   \n",
       "3             0.1231                    3       No Upfront     1       8   \n",
       "4             0.0721                    1  Partial Upfront     1       8   \n",
       "...              ...                  ...              ...   ...     ...   \n",
       "176003        4.1430                    3       No Upfront    64     976   \n",
       "176004        3.7550                    1  Partial Upfront    64     976   \n",
       "176005        3.3360                    1  Partial Upfront    64     976   \n",
       "176006        2.1700                    3  Partial Upfront    64     976   \n",
       "176007        4.6010                    3       No Upfront    64     976   \n",
       "\n",
       "       operatingSystem  networkPerformance EffectiveDate  DiskType  \\\n",
       "0              RHEL_HA                10.0    2021-03-01  NVMe SSD   \n",
       "1              RHEL_HA                10.0    2021-03-01  NVMe SSD   \n",
       "2              RHEL_HA                10.0    2021-03-01  NVMe SSD   \n",
       "3              RHEL_HA                10.0    2021-03-01  NVMe SSD   \n",
       "4              RHEL_HA                10.0    2021-03-01  NVMe SSD   \n",
       "...                ...                 ...           ...       ...   \n",
       "176003           Linux                 1.0    2021-01-01       SSD   \n",
       "176004           Linux                 1.0    2021-01-01       SSD   \n",
       "176005           Linux                 1.0    2021-01-01       SSD   \n",
       "176006           Linux                 1.0    2021-01-01       SSD   \n",
       "176007           Linux                 1.0    2021-01-01       SSD   \n",
       "\n",
       "        StorageSize  year  \n",
       "0                59  2021  \n",
       "1                59  2021  \n",
       "2                59  2021  \n",
       "3                59  2021  \n",
       "4                59  2021  \n",
       "...             ...   ...  \n",
       "176003         1920  2021  \n",
       "176004         1920  2021  \n",
       "176005         1920  2021  \n",
       "176006         1920  2021  \n",
       "176007         1920  2021  \n",
       "\n",
       "[176008 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.sort_values(by='EffectiveDate')\n",
    "data_all.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "if outlier == 'isolation':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit', 'vCPU', 'Memory']\n",
    "\n",
    "    # Create an Isolation Forest object\n",
    "    # Adjust the contamination parameter as needed\n",
    "    isolation_forest = IsolationForest(contamination=0.1)\n",
    "\n",
    "    # Fit the Isolation Forest model and predict outlier labels\n",
    "    outlier_labels = isolation_forest.fit_predict(data_all[columns_to_check])\n",
    "\n",
    "    # Identify outliers based on the predicted labels\n",
    "    outliers = data_all[outlier_labels == -1]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[outlier_labels != -1]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "if outlier == 'lof':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Create a LOF object\n",
    "    # Adjust parameters as needed\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "\n",
    "    # Fit the LOF model and predict outlier scores\n",
    "    outlier_scores = lof.fit_predict(data_all[columns_to_check])\n",
    "\n",
    "    # Identify outliers based on the predicted scores\n",
    "    outliers = data_all[outlier_scores == -1]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[outlier_scores != -1]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range (IQR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if outlier == 'iqr':\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Calculate the IQR for each column\n",
    "    Q1 = data_all[columns_to_check].quantile(0.25)\n",
    "    Q3 = data_all[columns_to_check].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define a threshold for identifying outliers\n",
    "    threshold = 2\n",
    "\n",
    "    # Determine the lower and upper bounds for outlier detection\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers by filtering the dataset\n",
    "    outliers = data_all[~((data_all[columns_to_check] >= lower_bound) & (\n",
    "        data_all[columns_to_check] <= upper_bound)).all(axis=1)]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all[((data_all[columns_to_check] >= lower_bound) & (\n",
    "        data_all[columns_to_check] <= upper_bound)).all(axis=1)]\n",
    "\n",
    "    # Print the outliers\n",
    "    print(\"Outliers:\")\n",
    "    print(outliers)\n",
    "\n",
    "    # Print the cleaned dataset\n",
    "    print(\"Cleaned Data:\")\n",
    "    print(data_all)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PricePerUnit  LeaseContractLength PurchaseOption  vCPU  Memory  \\\n",
      "9           20.96135                    1     No Upfront    64    2048   \n",
      "10          23.04293                    1     No Upfront    64    2048   \n",
      "11          16.01293                    3     No Upfront    64    2048   \n",
      "15          17.10160                    3     No Upfront    64    2048   \n",
      "49          13.36740                    1     No Upfront    64    1024   \n",
      "...              ...                  ...            ...   ...     ...   \n",
      "175891      13.72173                    3     No Upfront    96    3072   \n",
      "175895      15.60167                    3     No Upfront    96    3072   \n",
      "175953      16.72000                    1     No Upfront    64     192   \n",
      "175954      18.07500                    1     No Upfront    64     192   \n",
      "175959      13.10000                    3     No Upfront    64     192   \n",
      "\n",
      "       operatingSystem  networkPerformance EffectiveDate  DiskType  \\\n",
      "9              Windows                50.0    2022-05-01  NVMe SSD   \n",
      "10             Windows                50.0    2022-05-01  NVMe SSD   \n",
      "11             Windows                50.0    2022-05-01  NVMe SSD   \n",
      "15             Windows                50.0    2022-05-01  NVMe SSD   \n",
      "49               Linux                50.0    2022-09-01  NVMe SSD   \n",
      "...                ...                 ...           ...       ...   \n",
      "175891         Windows                75.0    2022-03-01  NVMe SSD   \n",
      "175895         Windows                75.0    2022-03-01  NVMe SSD   \n",
      "175953           Linux                10.0    2019-10-01       SSD   \n",
      "175954           Linux                10.0    2019-10-01       SSD   \n",
      "175959           Linux                10.0    2019-10-01       SSD   \n",
      "\n",
      "        StorageSize  year  \n",
      "9              1900  2022  \n",
      "10             1900  2022  \n",
      "11             1900  2022  \n",
      "15             1900  2022  \n",
      "49             1900  2022  \n",
      "...             ...   ...  \n",
      "175891         2850  2022  \n",
      "175895         2850  2022  \n",
      "175953         1920  2019  \n",
      "175954         1920  2019  \n",
      "175959         1920  2019  \n",
      "\n",
      "[23473 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "if outlier == 'zscore':\n",
    "\n",
    "    # Select the column(s) you want to detect outliers in\n",
    "    columns_to_check = ['PricePerUnit']\n",
    "\n",
    "    # Compute the Z-scores for each data point\n",
    "    z_scores = np.abs(stats.zscore(data_all[columns_to_check]))\n",
    "\n",
    "    # Define a threshold for identifying outliers\n",
    "    threshold = 0.75\n",
    "\n",
    "    # Find the indices of outliers\n",
    "    outlier_indices = np.where(z_scores > threshold)\n",
    "\n",
    "    # Get the rows containing outliers\n",
    "    outliers = data_all.iloc[outlier_indices[0]]\n",
    "\n",
    "    # Exclude outliers from the dataset\n",
    "    data_all = data_all.drop(data_all.index[outlier_indices[0]])\n",
    "\n",
    "    # Print the outliers\n",
    "    print(outliers)\n",
    "\n",
    "    mlflow.log_param(\"z-threshold\", threshold)\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create a quarterly seasonality column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert EffectiveDate column to datetime format\n",
    "data_all['EffectiveDate'] = pd.to_datetime(data_all['EffectiveDate'])\n",
    "\n",
    "# Extract the quarter component from the EffectiveDate column\n",
    "data_all['Quarter'] = data_all['EffectiveDate'].dt.quarter\n",
    "\n",
    "# Create a dictionary mapping quarter numbers to season labels\n",
    "seasons = {1: 'Q1', 2: 'Q2', 3: 'Q3', 4: 'Q4'}\n",
    "\n",
    "# Map the quarter numbers to season labels using the dictionary\n",
    "data_all['Seasonality'] = data_all['Quarter'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all\n",
    "\n",
    "data_all = data_all.drop(['Seasonality'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Years"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select which years will be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021, 2022, 2020, 2019, 2018, 2016, 2017])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred = data_all[data_all['year'] > 2021]\n",
    "data_pred = data_pred.sort_values(by='EffectiveDate')\n",
    "data_pred = data_pred.reset_index(drop=True)\n",
    "data_pred.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_all[(data_all['year'] > 2020) & (data_all['year'] < 2022)]\n",
    "data = data.sort_values(by='EffectiveDate')\n",
    "data = data.reset_index(drop=True)\n",
    "data.year.unique()\n",
    "\n",
    "\n",
    "mlflow.log_param(\"Years used to predict\", data.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PricePerUnit</th>\n",
       "      <th>LeaseContractLength</th>\n",
       "      <th>PurchaseOption</th>\n",
       "      <th>vCPU</th>\n",
       "      <th>Memory</th>\n",
       "      <th>operatingSystem</th>\n",
       "      <th>networkPerformance</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>DiskType</th>\n",
       "      <th>StorageSize</th>\n",
       "      <th>year</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6010</td>\n",
       "      <td>3</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>64</td>\n",
       "      <td>976</td>\n",
       "      <td>Linux</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>1920</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4401</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>Linux</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>NVMe SSD</td>\n",
       "      <td>1900</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3730</td>\n",
       "      <td>1</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>16</td>\n",
       "      <td>488</td>\n",
       "      <td>Linux</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>480</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5300</td>\n",
       "      <td>3</td>\n",
       "      <td>No Upfront</td>\n",
       "      <td>16</td>\n",
       "      <td>488</td>\n",
       "      <td>Linux</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>480</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6060</td>\n",
       "      <td>1</td>\n",
       "      <td>Partial Upfront</td>\n",
       "      <td>16</td>\n",
       "      <td>488</td>\n",
       "      <td>Linux</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>SSD</td>\n",
       "      <td>480</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PricePerUnit  LeaseContractLength   PurchaseOption  vCPU  Memory  \\\n",
       "0        4.6010                    3       No Upfront    64     976   \n",
       "1        0.4401                    3  Partial Upfront    32      26   \n",
       "2        3.3730                    1       No Upfront    16     488   \n",
       "3        1.5300                    3       No Upfront    16     488   \n",
       "4        1.6060                    1  Partial Upfront    16     488   \n",
       "\n",
       "  operatingSystem  networkPerformance EffectiveDate  DiskType  StorageSize  \\\n",
       "0           Linux                 1.0    2021-01-01       SSD         1920   \n",
       "1           Linux                10.0    2021-01-01  NVMe SSD         1900   \n",
       "2           Linux                10.0    2021-01-01       SSD          480   \n",
       "3           Linux                10.0    2021-01-01       SSD          480   \n",
       "4           Linux                10.0    2021-01-01       SSD          480   \n",
       "\n",
       "   year  Quarter  \n",
       "0  2021        1  \n",
       "1  2021        1  \n",
       "2  2021        1  \n",
       "3  2021        1  \n",
       "4  2021        1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categorical = ['PurchaseOption','OfferingClass', 'Location', 'Tenancy', 'operatingSystem', 'DiskType']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  =========== Prepare the Data for regression============\n",
    "\n",
    "# Map binary categorical columns to numerical\n",
    "\n",
    "categorical_binary = ['PurchaseOption']\n",
    "data[categorical_binary] = data[categorical_binary].apply(mf.binary_map)\n",
    "\n",
    "data_pred[categorical_binary] = data_pred[categorical_binary].apply(\n",
    "    mf.binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the categorical values as a list\n",
    "# categorical = ['operatingSystem', 'DiskType', 'Location']\n",
    "categorical = ['operatingSystem', 'DiskType']\n",
    "categorical2numeric = pd.get_dummies(data[categorical], drop_first=False)\n",
    "\n",
    "categorical2numeric_pred = pd.get_dummies(\n",
    "    data_pred[categorical], drop_first=False)\n",
    "\n",
    "# Add the above results to the original dataframe df\n",
    "data = pd.concat([data, categorical2numeric], axis=1)\n",
    "data.drop(columns=categorical, axis=1, inplace=True)\n",
    "\n",
    "data_pred = pd.concat([data_pred, categorical2numeric_pred], axis=1)\n",
    "data_pred.drop(columns=categorical, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(['PricePerUnit', 'EffectiveDate', 'year'], axis=1)\n",
    "y = data.PricePerUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # identify categorical features indices\n",
    "# def column_index(data, query_cols):\n",
    "#     cols = data.columns.values\n",
    "#     sidx = np.argsort(cols)\n",
    "#     return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]\n",
    "\n",
    "# categorical_features_indices = column_index(X, categorical)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoost Model Training\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca817fba96b478f8a4db5fe882131f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.2540778\ttest: 2.3448005\tbest: 2.3448005 (0)\ttotal: 1.08ms\tremaining: 53ms\n",
      "1:\tlearn: 2.1570302\ttest: 2.2441349\tbest: 2.2441349 (1)\ttotal: 2.18ms\tremaining: 52.4ms\n",
      "2:\tlearn: 2.0651308\ttest: 2.1479059\tbest: 2.1479059 (2)\ttotal: 3ms\tremaining: 47.1ms\n",
      "3:\tlearn: 1.9810610\ttest: 2.0609047\tbest: 2.0609047 (3)\ttotal: 3.75ms\tremaining: 43.2ms\n",
      "4:\tlearn: 1.9128393\ttest: 1.9895504\tbest: 1.9895504 (4)\ttotal: 4.57ms\tremaining: 41.1ms\n",
      "5:\tlearn: 1.8554993\ttest: 1.9307201\tbest: 1.9307201 (5)\ttotal: 5.46ms\tremaining: 40ms\n",
      "6:\tlearn: 1.8001804\ttest: 1.8718222\tbest: 1.8718222 (6)\ttotal: 6.25ms\tremaining: 38.4ms\n",
      "7:\tlearn: 1.7531242\ttest: 1.8228069\tbest: 1.8228069 (7)\ttotal: 7.02ms\tremaining: 36.9ms\n",
      "8:\tlearn: 1.7061397\ttest: 1.7735208\tbest: 1.7735208 (8)\ttotal: 7.87ms\tremaining: 35.8ms\n",
      "9:\tlearn: 1.6670902\ttest: 1.7322572\tbest: 1.7322572 (9)\ttotal: 8.61ms\tremaining: 34.4ms\n",
      "10:\tlearn: 1.6374011\ttest: 1.7016889\tbest: 1.7016889 (10)\ttotal: 9.47ms\tremaining: 33.6ms\n",
      "11:\tlearn: 1.6089653\ttest: 1.6705984\tbest: 1.6705984 (11)\ttotal: 10.3ms\tremaining: 32.7ms\n",
      "12:\tlearn: 1.5821410\ttest: 1.6416400\tbest: 1.6416400 (12)\ttotal: 11.3ms\tremaining: 32.3ms\n",
      "13:\tlearn: 1.5566289\ttest: 1.6150954\tbest: 1.6150954 (13)\ttotal: 12.2ms\tremaining: 31.5ms\n",
      "14:\tlearn: 1.5319955\ttest: 1.5899082\tbest: 1.5899082 (14)\ttotal: 13ms\tremaining: 30.3ms\n",
      "15:\tlearn: 1.5121576\ttest: 1.5694924\tbest: 1.5694924 (15)\ttotal: 13.6ms\tremaining: 29ms\n",
      "16:\tlearn: 1.4931313\ttest: 1.5507362\tbest: 1.5507362 (16)\ttotal: 14.3ms\tremaining: 27.8ms\n",
      "17:\tlearn: 1.4765414\ttest: 1.5336772\tbest: 1.5336772 (17)\ttotal: 15ms\tremaining: 26.6ms\n",
      "18:\tlearn: 1.4604915\ttest: 1.5173814\tbest: 1.5173814 (18)\ttotal: 15.7ms\tremaining: 25.6ms\n",
      "19:\tlearn: 1.4469472\ttest: 1.5040956\tbest: 1.5040956 (19)\ttotal: 16.5ms\tremaining: 24.8ms\n",
      "20:\tlearn: 1.4330603\ttest: 1.4899138\tbest: 1.4899138 (20)\ttotal: 17.3ms\tremaining: 23.8ms\n",
      "21:\tlearn: 1.4194881\ttest: 1.4766325\tbest: 1.4766325 (21)\ttotal: 17.9ms\tremaining: 22.8ms\n",
      "22:\tlearn: 1.4074328\ttest: 1.4650512\tbest: 1.4650512 (22)\ttotal: 18.7ms\tremaining: 21.9ms\n",
      "23:\tlearn: 1.3979271\ttest: 1.4547276\tbest: 1.4547276 (23)\ttotal: 19.6ms\tremaining: 21.3ms\n",
      "24:\tlearn: 1.3876785\ttest: 1.4442665\tbest: 1.4442665 (24)\ttotal: 20.3ms\tremaining: 20.3ms\n",
      "25:\tlearn: 1.3774523\ttest: 1.4339488\tbest: 1.4339488 (25)\ttotal: 21ms\tremaining: 19.4ms\n",
      "26:\tlearn: 1.3696352\ttest: 1.4263188\tbest: 1.4263188 (26)\ttotal: 21.6ms\tremaining: 18.4ms\n",
      "27:\tlearn: 1.3619773\ttest: 1.4188975\tbest: 1.4188975 (27)\ttotal: 22.2ms\tremaining: 17.4ms\n",
      "28:\tlearn: 1.3543456\ttest: 1.4114878\tbest: 1.4114878 (28)\ttotal: 22.8ms\tremaining: 16.5ms\n",
      "29:\tlearn: 1.3468973\ttest: 1.4038000\tbest: 1.4038000 (29)\ttotal: 23.4ms\tremaining: 15.6ms\n",
      "30:\tlearn: 1.3415368\ttest: 1.3992168\tbest: 1.3992168 (30)\ttotal: 24.2ms\tremaining: 14.8ms\n",
      "31:\tlearn: 1.3356121\ttest: 1.3923991\tbest: 1.3923991 (31)\ttotal: 25.1ms\tremaining: 14.1ms\n",
      "32:\tlearn: 1.3306068\ttest: 1.3871093\tbest: 1.3871093 (32)\ttotal: 25.9ms\tremaining: 13.3ms\n",
      "33:\tlearn: 1.3244069\ttest: 1.3804627\tbest: 1.3804627 (33)\ttotal: 26.6ms\tremaining: 12.5ms\n",
      "34:\tlearn: 1.3193476\ttest: 1.3759393\tbest: 1.3759393 (34)\ttotal: 27.4ms\tremaining: 11.7ms\n",
      "35:\tlearn: 1.3143181\ttest: 1.3711603\tbest: 1.3711603 (35)\ttotal: 28.1ms\tremaining: 10.9ms\n",
      "36:\tlearn: 1.3089347\ttest: 1.3647640\tbest: 1.3647640 (36)\ttotal: 28.7ms\tremaining: 10.1ms\n",
      "37:\tlearn: 1.3044369\ttest: 1.3601596\tbest: 1.3601596 (37)\ttotal: 29.3ms\tremaining: 9.26ms\n",
      "38:\tlearn: 1.2996452\ttest: 1.3556654\tbest: 1.3556654 (38)\ttotal: 30ms\tremaining: 8.46ms\n",
      "39:\tlearn: 1.2954849\ttest: 1.3516073\tbest: 1.3516073 (39)\ttotal: 30.6ms\tremaining: 7.65ms\n",
      "40:\tlearn: 1.2894883\ttest: 1.3461134\tbest: 1.3461134 (40)\ttotal: 31.2ms\tremaining: 6.85ms\n",
      "41:\tlearn: 1.2864779\ttest: 1.3429463\tbest: 1.3429463 (41)\ttotal: 31.8ms\tremaining: 6.06ms\n",
      "42:\tlearn: 1.2823662\ttest: 1.3389853\tbest: 1.3389853 (42)\ttotal: 32.5ms\tremaining: 5.28ms\n",
      "43:\tlearn: 1.2794313\ttest: 1.3357005\tbest: 1.3357005 (43)\ttotal: 33.1ms\tremaining: 4.51ms\n",
      "44:\tlearn: 1.2759532\ttest: 1.3325000\tbest: 1.3325000 (44)\ttotal: 33.7ms\tremaining: 3.74ms\n",
      "45:\tlearn: 1.2715107\ttest: 1.3275857\tbest: 1.3275857 (45)\ttotal: 34.3ms\tremaining: 2.98ms\n",
      "46:\tlearn: 1.2679954\ttest: 1.3237973\tbest: 1.3237973 (46)\ttotal: 34.9ms\tremaining: 2.23ms\n",
      "47:\tlearn: 1.2658039\ttest: 1.3217808\tbest: 1.3217808 (47)\ttotal: 35.5ms\tremaining: 1.48ms\n",
      "48:\tlearn: 1.2625544\ttest: 1.3183440\tbest: 1.3183440 (48)\ttotal: 36.1ms\tremaining: 736us\n",
      "49:\tlearn: 1.2610033\ttest: 1.3166879\tbest: 1.3166879 (49)\ttotal: 36.7ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.316687867\n",
      "bestIteration = 49\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f687d59f7f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=50, depth=3,\n",
    "                          learning_rate=0.1, loss_function='RMSE')\n",
    "\n",
    "# cat_features=categorical_features_indices\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=(X_valid, y_valid), plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Regressor parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000,\n",
    "                          loss_function='RMSE',\n",
    "                          # 0.001 - 0.1 A lower learning rate results in slower but more precise convergence\n",
    "                          learning_rate=0.001,\n",
    "                          # 4 - 10  Higher values allow the model to capture more complex interactions but can increase the risk of overfitting.\n",
    "                          depth=16,\n",
    "                          custom_metric=['MAPE', 'RMSE', 'MAE', 'R2'],\n",
    "                          random_seed=42,\n",
    "                          bagging_temperature=0.2,  # 0 - 1\n",
    "                          # Can be 'Iter' or 'IncToDec'. 'Iter' stops training when the evaluation metric stops improving, and 'IncToDec' stops when the evaluation metric starts to worsen.\n",
    "                          od_type='Iter',\n",
    "                          metric_period=75,  # how frequently the evaluation metric is calculated during training\n",
    "                          task_type='CPU',  # Enable GPU training\n",
    "                          # number of iterations to wait for the evaluation metric to improve before stopping training.\n",
    "                          od_wait=100,\n",
    "                          )\n",
    "\n",
    "# Log specific parameters of the CatBoost model\n",
    "params_to_track = ['iterations', 'learning_rate', 'depth', 'loss_function', 'bagging_temperature',\n",
    "                   'random_seed', 'metric_period', 'od_wait', 'task_type']\n",
    "for param in params_to_track:\n",
    "    param_value = model.get_params().get(param)\n",
    "    mlflow.log_param(param, str(param_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4bef4020674dcfb2423bfa2bd4fd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3666335\ttest: 2.4611334\tbest: 2.4611334 (0)\ttotal: 41.5ms\tremaining: 41.4s\n",
      "75:\tlearn: 2.2478953\ttest: 2.3429739\tbest: 2.3429739 (75)\ttotal: 6.03s\tremaining: 1m 13s\n",
      "150:\tlearn: 2.1385035\ttest: 2.2339582\tbest: 2.2339582 (150)\ttotal: 10.2s\tremaining: 57.3s\n",
      "225:\tlearn: 2.0379150\ttest: 2.1340185\tbest: 2.1340185 (225)\ttotal: 16s\tremaining: 54.9s\n",
      "300:\tlearn: 1.9460132\ttest: 2.0427733\tbest: 2.0427733 (300)\ttotal: 21.8s\tremaining: 50.7s\n",
      "375:\tlearn: 1.8620403\ttest: 1.9595139\tbest: 1.9595139 (375)\ttotal: 28.3s\tremaining: 47s\n",
      "450:\tlearn: 1.7850830\ttest: 1.8832577\tbest: 1.8832577 (450)\ttotal: 35s\tremaining: 42.7s\n",
      "525:\tlearn: 1.7152567\ttest: 1.8141162\tbest: 1.8141162 (525)\ttotal: 41.4s\tremaining: 37.3s\n",
      "600:\tlearn: 1.6513412\ttest: 1.7508339\tbest: 1.7508339 (600)\ttotal: 49.2s\tremaining: 32.6s\n",
      "675:\tlearn: 1.5930643\ttest: 1.6930886\tbest: 1.6930886 (675)\ttotal: 56.3s\tremaining: 27s\n",
      "750:\tlearn: 1.5401098\ttest: 1.6404195\tbest: 1.6404195 (750)\ttotal: 1m 3s\tremaining: 21.2s\n",
      "825:\tlearn: 1.4922985\ttest: 1.5928736\tbest: 1.5928736 (825)\ttotal: 1m 12s\tremaining: 15.2s\n",
      "900:\tlearn: 1.4490513\ttest: 1.5499996\tbest: 1.5499996 (900)\ttotal: 1m 19s\tremaining: 8.74s\n",
      "975:\tlearn: 1.4099708\ttest: 1.5113850\tbest: 1.5113850 (975)\ttotal: 1m 29s\tremaining: 2.19s\n",
      "999:\tlearn: 1.3983298\ttest: 1.4998180\tbest: 1.4998180 (999)\ttotal: 1m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.499818027\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f67fdc28d60>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          eval_set=(X_valid, y_valid),\n",
    "          use_best_model=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.catboost.log_model(model, \"catboost_model\")\n",
    "\n",
    "best_iteration = model.get_best_iteration()\n",
    "\n",
    "mlflow.log_metric('best_iteration', best_iteration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': X.columns})\n",
    "fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[\n",
    "                              True, False]).iloc[-30:]\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "    x=fea_imp['imp'],\n",
    "    y=fea_imp['col'],\n",
    "    orientation='h',\n",
    "    marker=dict(color=fea_imp['imp'], colorbar=dict(title='Importance'))\n",
    "\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CatBoost - Feature Importance - All',\n",
    "    yaxis=dict(title='Features'),\n",
    "    xaxis=dict(title='Importance'),\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"feature_importance_all.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log feature importance - mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance values and feature names from your CatBoost model\n",
    "feature_importance = model.get_feature_importance()\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame to store the feature importance values and feature names\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "# Create a temporary file to save the feature importance DataFrame\n",
    "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as temp_file:\n",
    "    # Save the feature importance DataFrame as a CSV file\n",
    "    feature_importance_df.to_csv(temp_file, index=False)\n",
    "\n",
    "# Log the feature importance CSV file as an artifact in MLflow\n",
    "mlflow.log_artifact(temp_file.name, \"feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import tempfile\n",
    "\n",
    "# # Define the years sets\n",
    "# years_sets = [\n",
    "#     [2020, 2021],\n",
    "#     [2019, 2020, 2021],\n",
    "#     [2018, 2019, 2020, 2021],\n",
    "#     [2021]\n",
    "# ]\n",
    "\n",
    "# # Create a DataFrame to store the feature importance values and feature names\n",
    "# feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "# # Insert the year sets as the first column in the DataFrame\n",
    "# feature_importance_df.insert(0, 'Year Sets', years_sets)\n",
    "\n",
    "# # Create a temporary file to save the feature importance DataFrame\n",
    "# with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as temp_file:\n",
    "#     # Save the feature importance DataFrame as a CSV file\n",
    "#     feature_importance_df.to_csv(temp_file, index=False)\n",
    "\n",
    "# # Log the feature importance CSV file as an artifact in MLflow\n",
    "# mlflow.log_artifact(temp_file.name, \"feature_importance.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Model evaluation:')\n",
    "print(model.get_params())\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_valid, model.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_best_score())\n",
    "\n",
    "# Flatten and log the best scores as parameters in MLflow\n",
    "best_scores = model.get_best_score()\n",
    "for stage, metrics in best_scores.items():\n",
    "    for metric, value in metrics.items():\n",
    "        mlflow.log_metric(f'{stage}_{metric}', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the MLflow run\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish without shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# pool = cb.Pool(X_valid, y_valid)\n",
    "\n",
    "\n",
    "# # Compute SHAP values\n",
    "# shap_values = model.get_feature_importance(pool, type='ShapValues')\n",
    "\n",
    "# # Convert SHAP values to a DataFrame\n",
    "# shap_df = pd.DataFrame(shap_values[:, :-1], columns=X_valid.columns)\n",
    "\n",
    "# # Log the SHAP values as an artifact in MLflow\n",
    "# shap_df.to_csv(\"shap_values.csv\", index=False)\n",
    "# mlflow.log_artifact(\"shap_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude the constant offset column from shap_values\n",
    "# shap_values = shap_values[:, :-1]\n",
    "\n",
    "# # Create a SHAP summary plot\n",
    "# shap.summary_plot(shap_values, X_valid)\n",
    "\n",
    "# # Save the plot as an artifact in MLflow\n",
    "# shap_plot_path = 'shap_summary_plot.png'\n",
    "# shap.summary_plot(shap_values, X_valid, show=False)\n",
    "# plt.savefig(shap_plot_path)\n",
    "# mlflow.log_artifact(shap_plot_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs Actual Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_pred_tmp = data_pred.drop(['PricePerUnit'], axis=1)\n",
    "predictions = model.predict(data_pred)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predictions'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Log the predictions CSV file as an artifact in MLflow\n",
    "mlflow.log_artifact('predictions.csv', 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_prices = data_pred.PricePerUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a line plot using Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(len(actual_prices))),\n",
    "              y=actual_prices, mode='lines', name='Actual'))\n",
    "fig.add_trace(go.Scatter(x=list(range(len(predictions))),\n",
    "              y=predictions, mode='lines', name='Predicted'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Prices for 2022',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='Price')\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"actual_predicted.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(actual_prices, predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = actual_prices - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(actual_prices, predictions, c=error, cmap='coolwarm')\n",
    "plt.plot(np.linspace(min(actual_prices), max(actual_prices), 100), np.linspace(\n",
    "    min(actual_prices), max(actual_prices), 100), color='black', linestyle='--')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot using Plotly\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=actual_prices,\n",
    "    y=predictions,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=error,\n",
    "        colorscale='Viridis',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title='Error')\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Prices',\n",
    "    xaxis=dict(title='Actual Prices'),\n",
    "    yaxis=dict(title='Predicted Prices')\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# Save the Plotly figure as an HTML file\n",
    "html_path = \"actual_predicted_errors.html\"\n",
    "pio.write_html(fig, html_path)\n",
    "\n",
    "# Log the HTML file as an artifact in MLflow\n",
    "mlflow.log_artifact(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "mse = mean_squared_error(actual_prices, predictions)\n",
    "rmse = mean_squared_error(actual_prices, predictions, squared=False)\n",
    "mae = mean_absolute_error(actual_prices, predictions)\n",
    "r2 = r2_score(actual_prices, predictions)\n",
    "mape = mean_absolute_percentage_error(actual_prices, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"MSE\", mse)\n",
    "mlflow.log_metric(\"RMSE\", rmse)\n",
    "mlflow.log_metric(\"MAE\", mae)\n",
    "mlflow.log_metric(\"MAPE\", mape)\n",
    "mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "# mlflow.log_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print('MAPE:', mape)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/ad-demand-forecast-with-catboost-lightgbm-819e5073cd3e\n",
    "\n",
    "https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# End the MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price3.9_env",
   "language": "python",
   "name": "price3.9_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
